<template>
<div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <h1>In the Age of A.I., What Makes People Unique?</h1>
    <h1>在人工智能时代，是什么让人与众不同？</h1>
  </div>
  <div class='parag' :style="{gridTemplateColumns: gridTemplateColumns,  marginBottom: '24px'}">
    <h5>More than ever, we’re challenged to define what’s valuable about being human.</h5>
    <h5>我们比以往任何时候都面临着这样的挑战： 界定作为人类的可贵之处。</h5>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Recently, I got a haircut, and my barber and I started talking about A.I. “It’s incredible,” he told me. “I just used it to write a poem for my girl’s birthday. I told it what to say, but I can’t rhyme that well, so it did all the writing. When she read the poem, she actually cried! Then she showed it to her friend, who’s really smart, and I thought, Uh-oh, she’ll figure it out for sure.” Snip, snip, snip, snip. “She didn’t.”</p>
    <p>最近我去理了发，我和理发师聊起了人工智能。“真是不可思议，”他告诉我，“我刚用它给我女朋友写了首生日诗。我告诉它要写什么，但我不会押韵，所以都是它写的。她读了那首诗后，居然哭了！然后她拿给她的一个很聪明的朋友看，我当时就想，这下糟了，肯定要被识破。”咔嚓，咔嚓，咔嚓，咔嚓。“结果并没有。”</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Everyone in the barbershop laughed, a little darkly. Writing poems that make your girl cry—add that to the list of abilities that used to make (some) humans unique but no longer do. Today’s A.I. systems can generate acceptable poetry, code, essays, and jokes; carry on useful conversations about economics, existentialism, and the Middle East; and even perform some aspects of scientific work, such as planning experiments, predicting outcomes, and interpreting results. They can make judgments about complex situations—traffic patterns, investments—at superhuman speed. In truth, we don’t yet know all they can do. The biggest tech companies are racing to deploy the technology partly so that we can find out.</p>
    <p>理发店里每个人都笑了，只是这笑里带着一丝阴郁。写出让女友哭泣的诗——这也算是一项曾经让（某些）人类与众不同但现在却不再独有的能力了。如今的人工智能系统能够创作出拿得出手的诗歌、代码、散文和笑话；能够就经济学、生存主义和中东局势等话题进行有意义的对话；甚至还能完成科研工作的某些环节，比如设计实验、预测结果和解读数据。它们能以超乎人类的速度对复杂的局面——比如交通模式或投资状况——做出判断。事实上，我们还不清楚人工智能究竟能做些什么。科技巨头们正竞相推广这项技术，某种程度上说就是为了弄清楚这个问题。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>It seems entirely likely that the list of A.I.’s capabilities will only grow—and so it’s tempting to wonder what, exactly, people are good for. In the past, theologians and philosophers compared us with animals and identified the ways in which we surpassed them. Now the tables aren’t so much turned as upended. In some cases, we seem to be looking upward at the machines (no human being can write with an A.I.’s fluidity and speed, for example). In others, we scratch our heads at their stupidity (no person would advise you to make a daily habit of eating “at least one small rock,” as Google’s A.I. did not long ago, when asked “How many rocks should I eat each day?”). In still other cases, we’re simply confused by the divergences between artificial and organic reasoning. An A.I. can’t fall in love, but it can express the idea of love; it can’t be an artist, but it can (maybe) create a kind of art; it can’t agonize over a consequential decision, but it can still decide. We know that there are crucial differences between a thinking computer and a person, but defining those distinctions isn’t easy.</p>
    <p>似乎可以肯定的是，AI的能力清单只会继续增长——这会让人忍不住思考，人类到底擅长什么。在过去，神学家和哲学家将我们与动物进行比较，并指出了我们超越它们的地方。而现在，情况已经完全颠倒了过来。在某些情况下，我们似乎只能仰望机器（比如，没有任何人类能够像 AI 那样行云流水、快速地写作）。而在另一些情况下，机器的愚蠢又让我们摸不着头脑（比如不久前，当被问及“我每天应该吃多少块石头？”的时候，谷歌的 AI 居然建议“每天至少吃一块小石头”）。还有一些时候，我们对机器与人类之间推理方式的不同感到困惑不解。AI 无法坠入爱河，但它却能表达爱的概念；它成不了艺术家，但也许能创作出某种艺术作品；它不会为一个重大的决定辗转反侧，但却依然能做出决定。我们知道，一台会思考的计算机与一个人类之间存在着根本的区别，但要明确这些区别并不容易。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>And yet this abstract conundrum has practical implications. As artificial intelligence proliferates, more and more hinges on our ability to articulate our own value. We seem to be on the cusp of a world in which workers of all kinds—teachers, doctors, writers, photographers, lawyers, coders, clerks, and more—will be replaced with, or to some degree sidelined by, their A.I. equivalents. What will get left out when A.I. steps in?</p>
    <p>而这一抽象的难题具有实际的影响。随着人工智能的普及，越来越多的事情取决于我们阐明自身价值的能力。我们似乎正处于一个各类工作者——教师、医生、作家、摄影师、律师、程序员、文员等等——将被人工智能取代或在一定程度上被排挤出局的世界的边缘。当人工智能介入时，会遗漏什么呢？</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>In “A.I. Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference,” two computer scientists, Arvind Narayanan and Sayash Kapoor, approach the question on a practical level. They urge skepticism, and argue that the blanket term “A.I.” can serve as a kind of smoke screen for underperforming technologies. “Imagine an alternate universe in which people don’t have words for different forms of transportation—only the collective noun ‘vehicle,’ ” they write. Such a world sees “furious debates about whether or not vehicles are environmentally friendly, even though no one realizes that one side of the debate is talking about bikes and the other side is talking about trucks.” Similarly, they write, the term “A.I.” encompasses a variety of technologies with wildly different levels of competence.</p>
    <p>在《人工智能的夸大其词：能做什么，不能做什么，如何辨别真伪》一书中，两位计算机科学家阿文德·纳拉亚南和萨亚什·卡普尔从实用的角度探讨了这个问题。他们提倡持怀疑态度，并认为“人工智能”这个总称可能为表现不尽如人意的技术打掩护。“设想一个平行宇宙，”他们写道，“在这个宇宙里人们没有不同的交通方式的说法，只有一个统称‘交通工具’。”这样的世界里会出现“激烈的争论，讨论交通工具是否环保，尽管没人意识到辩论的一方说的是自行车，而另一方说的是卡车。”他们还写道，同样地，“人工智能”这个词涵盖了多种技术水平参差不齐的技术。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Narayanan and Kapoor are particularly wary of predictive artificial intelligence, which is designed to make guesses about the future. Unlike generative A.I.—the relatively new technology used in ChatGPT and the like—predictive A.I. is already integrated into our lives to a surprising extent. Human-resources departments use it to suggest which candidates will succeed on the job; hospitals employ it to help decide who should be sent home or admitted for a stay. And yet predictive A.I. systems are almost never rigorously and independently tested; when they are, they often fail. Narayanan and Kapoor recount the findings of researchers investigating an A.I. system called Retorio, which claims to predict future on-the-job behavior, and thus performance, by analyzing video interviews with job candidates. It turned out that wearing glasses or a scarf, sitting in front of some bookshelves, or sending a résumé in the form of a PDF could drastically change a candidate’s score. Wearing glasses “obviously does not change someone’s capability to perform well at a job,” the authors write. In their view, the system is A.I. snake oil.</p>
    <p>纳拉亚南和卡普尔尤其警惕预测型人工智能，这种技术旨在对将来做出预测。与生成式 AI（ChatGPT 等应用所采用的相对较新的技术）不同，预测型 AI 已经在我们生活中占据了令人惊讶的比例。人力资源部门利用它来推测哪些求职者会在工作中取得成功；医院则用它来帮助决定哪些病人可以回家、哪些需要住院治疗。然而，预测型 AI 几乎从未经过严格独立的测试；一旦经过测试，往往会发现它们并不靠谱。纳拉亚南和卡普尔提到了一些研究人员的发现，他们调查了一款名为 Retorio 的 AI 系统，该系统号称通过分析求职者的视频面试就可以预测其未来的工作表现。结果发现，戴眼镜或围巾、坐在书架前或以 PDF 形式发送简历都会极大地改变求职者的得分。作者写道，很显然，“戴眼镜并不会改变一个人胜任工作的能力”。在他们看来，这套系统就是 AI 版的江湖骗术。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>The problems with predictive A.I. can run deeper than mere inaccuracy. In an early experiment, researchers built a system for guessing whether pneumonia patients arriving at a hospital would need overnight care. The system examined the data and discovered that patients with asthma tended to recover from pneumonia faster; this made it more likely to recommend that asthmatic patients be sent home. That’s a crazy recommendation, of course; the correlation on which it’s based reflects the fact that asthmatic people with pneumonia are often admitted directly to the I.C.U., where they receive high levels of care. (The system was never used.) “A good prediction is not a good decision,” Narayanan and Kapoor write. Among other things, being a capable decision-maker means not just interrogating the origins of your intuitions, but also imagining how your upcoming decisions might render those intuitions invalid. It’s highly unlikely that candidates who Zoom while sitting in front of bookshelves will be better employees—but, even if that prediction were true, acting on it repeatedly would simply teach interviewees to sit in front of bookshelves. As human beings, we have a sense of the fallibility of our thinking; it’s one of our strengths.</p>
    <p>预测型人工智能的问题可能比单纯的不准确更为严重。在早期的一项实验中，研究人员建立了一个系统来猜测到达医院的肺炎患者是否需要过夜治疗。该系统检查了数据后发现，患有哮喘的病人往往能更快地从肺炎中恢复过来；这使得它更有可能建议将哮喘患者送回家。当然，这是一个荒谬的建议；其依据的相关性反映出患肺炎的哮喘患者通常会被直接送入重症监护室，在那里接受高级别的治疗的事实。（该系统从未被使用过）“一个好的预测并不等同于一个好的决定”，纳拉亚南和卡普尔写道。成为一名有能力的决策者意味着不仅要探究直觉的来源，还要想象即将做出的决定如何使这些直觉变得无效。坐在书架前通过Zoom面试的候选人更有可能成为优秀的员工，这种可能性极低——但即便这一预测是真的，一再根据它行事只会教会应聘者坐在书架前。作为人类，我们对自己的思维方式存在缺陷有着一种认识；这是我们的优势之一。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Shannon Vallor, a philosopher at the University of Edinburgh who has worked as an A.I. ethicist at Google, doesn’t enumerate the failures of A.I. so much as explore the range and potency of human virtues. In “The A.I. Mirror: How to Reclaim Our Humanity in an Age of Machine Thinking,” she argues that we vastly underestimate our own richness compared with that of A.I. “Consider the image that appears in your bathroom mirror every morning,” she writes. It isn’t a copy of your body, or an imitation of it; it’s just a reflection. Similarly, today’s A.I. systems “don’t produce thoughts or feelings any more than mirrors produce bodies. What they produce is a new kind of reflection.”</p>
    <p>爱丁堡大学哲学家瓦洛尔曾是谷歌的人工智能伦理学家，她没有列举人工智能的种种失败，而是探讨了人类美德的多样性和强大力量。在《人工智能之镜：如何在一个机器思维的时代重获人性》一书中，她认为我们大大低估了自身拥有的丰富性，而这种丰富性是人工智能所不具备的。“想想每天早晨出现在浴室镜子里的身影吧，”她写道，那并不是你身体的复制品或仿造品，那只是一个映像。同样地，如今的人工智能系统“产生的并非思想或情感，就好比镜子不会产生人体一样。它们产生的是一种新的映像。”</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Vallor specializes not just in the philosophy of technology but also in virtue ethics—the study of what it means for a person to have excellent qualities. She notes that cultivating virtues—courage, honesty, integrity, imagination, empathy, curiosity, and so on—takes time. Being virtuous isn’t something you achieve once; it’s not like passing a test. It involves navigating the world in a certain way with particular priorities in mind, while asking endless questions about what you should do, how you should do it, who you should do it with, and why you’re doing it. “This struggle is the root of existentialist philosophy,” Vallor writes. “At each moment we must choose to exist in a particular way. Then, even as we make the choice—to love another, to shoulder a duty, to take up a cause, to rebuke a faith or throw ourselves into it—the choice opens up again. It will not hold itself there without our commitment to choose it again, and again.”</p>
    <p>瓦勒不仅专注于技术哲学，还专注于美德伦理学——即研究一个人具备优秀品质意味着什么的学问。她指出，培养诸如勇气、诚实、正直、想象力、同理心、好奇心等美德需要时间。拥有美德不是一次就能成就的事；那可不是通过一场考试那么简单。它涉及以某种方式来认识世界，并且心中牢记特定的价值观，同时不断追问自己应该做什么、如何去做、和谁一起做以及为何这样做。“这种挣扎正是存在主义哲学的核心，”瓦勒写道，“在每一刻，我们都必须选择一种生存方式。然后，即便我们做出了选择——去爱一个人、承担起一项责任、投身于一项事业、质疑或全身心投入一种信仰——这种选择也会再次出现。如果没有我们一次次地承诺重新做出同样的选择，这种选择是不会自动延续下去的。”</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>In Vallor’s view, though A.I. systems have many striking capabilities, they don’t have the ability to be virtuous. This may not sound like a big deal, but in fact it’s profound. Being loving is a virtue, and people can spend their whole lives trying to love one another better. But, when a chatbot says, “I’ve been missing you all day,” Vallor writes, “it’s bullshit since the chatbot doesn’t have a concept of emotional truth to betray.” The bot is putting itself across as a being capable of love, but the words are unearned. “A flat digital mirror has no bodily depth that can ache,” she argues. “It knows no passage of time that can drag.” In short, it isn’t alive—and without having a life, it can’t be any way in particular.</p>
    <p>在瓦洛看来，尽管人工智能系统拥有许多显著的能力，但它们不具备道德品性。这听上去似乎没什么大不了的，但事实上意义深远。有爱是一种美德，人们可能终其一生都在努力更好地去爱他人。但是，当聊天机器人说“我一整天都在想你”时，瓦洛写道，这是“胡扯”，因为聊天机器人根本没有可以违背的“情感真实”的概念。机器人把自己表现为能够去爱的生命体，但这些言语是空洞无物的。“一块扁平的数字镜子没有会痛的躯体深处，”她辩称，“它不懂得时间流逝。”简而言之，它没有生命——而没有生命，也就没有特定的存在方式。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Vallor’s worry isn’t that artificially intelligent computers will rise up and dominate humanity, but that, faced with computers that can pretend to have human virtues, we’ll lose track of what those virtues really are. Comforted by computers that tell us that they love us, we’ll forget what love is. Wowed by systems that seem to be creative, we’ll lose respect for actual human creativity—a struggle for self-expression that can involve a “painful” reimagining of the self. This forgetting process, she warns, has already begun: besotted with our technology, we seem almost eager to narrow our conception of what it means to be human. “The call is coming from inside the house,” Vallor writes. “AI can devalue our humanity only because we already devalued it ourselves.” We need to reinvest in the vocabulary of human value before our machines rob it of its meaning.</p>
    <p>瓦勒担忧的不是人工智能计算机将崛起并统治人类，而是面对能够佯装拥有做人美德的计算机，我们会忘却这些美德的真正含义。在那些对我们说爱我们的计算机的安慰下，我们会忘记爱是什么。对那些看似具有创造性的系统赞叹不已，我们会失去对真正的人类创造力的尊重——而这种自我表达的奋斗可能包含对自我的“痛苦”的重塑。她提醒我们，这一遗忘过程已经开始了：对技术痴迷的我们似乎急切地想要狭隘地定义做人的意义。“来电显示是家里号码，”瓦勒写道，“人工智能之所以会贬低我们的人性价值，只是因为我们自己首先贬低了它。”我们需要重新投资于描述人性价值的话语体系，以免被机器剥夺其意义。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>Compared with many technologists, Narayanan, Kapoor, and Vallor are deeply skeptical about today’s A.I. technology and what it can achieve. Perhaps they shouldn’t be. Some experts—including Geoffrey Hinton, the “godfather of A.I.,” whom I profiled recently—believe that it might already make sense to talk about A.I.s that have emotions or subjective points of view. Around the world, billions of dollars are being spent to make A.I. more powerful. Perhaps systems with more complex minds—with memories, goals, moral commitments, higher purposes, and so on—can be built.</p>
    <p>与许多技术专家相比，纳拉亚南、卡普尔和瓦勒对当下的人工智能技术和它所能实现的成就抱有深深的怀疑。也许他们不该如此。一些专家——包括我最近描述过的、“人工智能之父”杰弗里·辛顿——认为，讨论拥有人类情感或主观视角的人工智能也许已经合情合理。全世界正在投入数十亿资金用于提升人工智能的能力。也许可以建立拥有更复杂心智的系统——即拥有记忆、目标、道德责任、更高追求等等。</p>
  </div>
  <div class='parag' :style="{ gridTemplateColumns: gridTemplateColumns }">
    <p>And yet these books aren’t just describing A.I., which continues to evolve, but characterizing the human condition. That’s work that can’t be easily completed, although the history of thought overflows with attempts. It’s hard because human life is elusive, variable, and individual, and also because characterizing human experience pushes us to the edges of our own expressive abilities. And so, probably, the polarity of our conversations about A.I. should be reversed. Instead of assuming that we know what human beings do, we should presume that, whenever an A.I. replaces a person in some role or other, something—perhaps a great deal—is lost. We should see the abilities of an A.I. as powerful, but never really humanlike. We should grow newly comfortable with asserting that human nature is indispensable, and take pride in the fact that we must struggle to define it.</p>
    <p>然而这些著作不仅仅是在描述持续进化的 AI，而是在描绘人类的生存状态。这项工作难以完成，尽管思想史上不乏尝试。之所以难是因为人的生命捉摸不定、千差万别、各具特色；也是因为要描绘人类的经历就会触及我们表达能力的极限。因此，关于 AI 的讨论或许应该颠倒过来。我们不该想当然地认为我们知道人类能做什么，而应假定每当 AI 在某个岗位上取代了人类，总会失去些什么——也许是很多东西。我们应该认为 AI 的能力虽强，却从来都称不上像人。我们应该欣然主张人性不可或缺，并为我们必须努力定义它而自豪。</p>
  </div>
</div>
</template>
<script>export default {  props: {    gridTemplateColumns: {      type: String,      required: true,    },  },};</script>